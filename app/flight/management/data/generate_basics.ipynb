{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import csv\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "def load_settings(file_path):\n",
    "    with open(file_path, \"r\") as stream:\n",
    "        try:\n",
    "            settings = yaml.safe_load(stream)\n",
    "            return settings\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(f\"Error loading YAML file: {exc}\")\n",
    "\n",
    "\n",
    "file_path = \"../../../settings.yml\"\n",
    "settings = load_settings(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEDULE_FILE = \"schedule_table.csv\"\n",
    "FLIGHT_FILE = \"flight_inventory_table.csv\"\n",
    "PNR_FILE = \"pnr_table.csv\"\n",
    "PASSENGER_FILE = \"passenger_table.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_df = pd.read_csv(SCHEDULE_FILE) # df_sch\n",
    "flight_df = pd.read_csv(FLIGHT_FILE) # df_inv\n",
    "pnr_df = pd.read_csv(PNR_FILE) # df_pnrb\n",
    "passenger_df = pd.read_csv(PASSENGER_FILE) # df_pnrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FC_CD': ['F', 'P'],\n",
       " 'BC_CD': ['C', 'J', 'Z'],\n",
       " 'PC_CD': ['R', 'M', 'S', 'Q', 'H', 'T'],\n",
       " 'EC_CD': ['L',\n",
       "  'G',\n",
       "  'K',\n",
       "  'A',\n",
       "  'U',\n",
       "  'N',\n",
       "  'O',\n",
       "  'V',\n",
       "  'I',\n",
       "  'W',\n",
       "  'X',\n",
       "  'Y',\n",
       "  'D',\n",
       "  'B',\n",
       "  'E']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cabins = \"FC_CD,BC_CD,PC_CD,EC_CD\".split(\",\")\n",
    "classes = {}\n",
    "for k in cabins:\n",
    "    classes[k] = []\n",
    "\n",
    "for cabin in cabins:\n",
    "    for i in range(len(flight_df)):\n",
    "        classes[cabin] += list(ast.literal_eval(flight_df[cabin][i]).keys())\n",
    "    classes[cabin] = list(set(classes[cabin]))\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# populate cabin.csv and class.csv\n",
    "cabin_df = pd.DataFrame(columns=[\"abb\", \"des\", \"score\"])\n",
    "class_df = pd.DataFrame(columns=[\"abb\", \"des\", \"score\", \"cabin\"])\n",
    "\n",
    "cabin_data, class_data = [], []\n",
    "\n",
    "cabins = {\n",
    "    \"F\": \"First Class\",\n",
    "    \"B\": \"Business Class\",\n",
    "    \"P\": \"Premium Economy\",\n",
    "    \"E\": \"Economy\",\n",
    "}\n",
    "\n",
    "for cabin in cabins:\n",
    "    cabin_data.append(\n",
    "        {\n",
    "            \"abb\": cabin,\n",
    "            \"des\": cabins[cabin],\n",
    "            \"score\": int(settings[\"scores\"][\"cabins\"][cabin]),\n",
    "        }\n",
    "    )\n",
    "    key = f\"{cabin}C_CD\"\n",
    "    for c in classes[key]:\n",
    "        class_data.append(\n",
    "            {\n",
    "                \"abb\": c,\n",
    "                \"des\": f\"{cabins[cabin]} - {c}\",\n",
    "                \"score\": int(settings[\"scores\"][\"cabins\"][cabin]),\n",
    "                \"cabin\": cabin,\n",
    "            }\n",
    "        )\n",
    "\n",
    "cabin_df = pd.concat([cabin_df, pd.DataFrame(cabin_data)]).to_csv(\n",
    "    \"cabin.csv\", index=False\n",
    ")\n",
    "class_df = pd.concat([class_df, pd.DataFrame(class_data)]).to_csv(\n",
    "    \"class.csv\", index=False\n",
    ")\n",
    "# print(cabin_df, class_df)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CarrierCodes\n",
    "cc_column_name = \"CarrierCode\"\n",
    "carrier = []\n",
    "carrier_df = pd.DataFrame(columns=[\"code\", \"desc\"])\n",
    "\n",
    "for i in range(len(flight_df)):\n",
    "    carrier.append(flight_df[cc_column_name][i])\n",
    "\n",
    "carrier_data = []\n",
    "carriers = list(set(carrier))\n",
    "for carrier in carriers:\n",
    "    carrier_data.append({\"code\": carrier, \"desc\": f\"carrier_{carrier}\"})\n",
    "\n",
    "carrier_df = pd.concat([carrier_df, pd.DataFrame(carrier_data)]).to_csv(\n",
    "    \"carrier.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default_ssr_score': 200,\n",
       " 'default_scd2_score': 300,\n",
       " 'default_scd3_score': 200,\n",
       " 'cabins': {'F': 2000, 'B': 1000, 'P': 500, 'E': 100},\n",
       " 'loyalty': {'Silver': 1000, 'Gold': 2000, 'Platinum': 3000}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings[\"scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38040/3262773731.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ssr_df = pd.concat([ssr_df, pd.DataFrame(ssr_data)]).to_csv(\"ssr.csv\", index=False)\n"
     ]
    }
   ],
   "source": [
    "# find ssrs and groups\n",
    "ssr_column_name, ss_cd1, ss_cd2 = \"SSR_CODE_CD1\", \"SPECIAL_NAME_CD2\", \"SPECIAL_NAME_CD1\"\n",
    "ssr, s_cd1, s_cd2 = [], [], []\n",
    "\n",
    "for i in range(len(passenger_df)):\n",
    "    ssr.append(passenger_df[ssr_column_name][i])\n",
    "    s_cd1.append(passenger_df[ss_cd1][i])\n",
    "    s_cd2.append(passenger_df[ss_cd2][i])\n",
    "\n",
    "ssr, s_cd2, s_cd1 = list(set(ssr)), list(set(s_cd2)), list(set(s_cd1))\n",
    "# ssr, s_cd2, s_cd1\n",
    "ssr_df = pd.DataFrame(columns=[\"abb\", \"des\", \"score\", \"prob\"])\n",
    "ssr_data = []\n",
    "ssr.pop(0)  # remove nan\n",
    "\n",
    "for ss in ssr:\n",
    "    ssr_data.append(\n",
    "        {\n",
    "            \"abb\": ss,\n",
    "            \"des\": f\"SSR_{ss}\",\n",
    "            \"score\": int(settings[\"scores\"][\"default_ssr_score\"]),\n",
    "            \"prob\": float(settings[\"probabilities\"][\"default_ssr_probability\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "ssr_df = pd.concat([ssr_df, pd.DataFrame(ssr_data)]).to_csv(\"ssr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 90)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch unique aircrafts\n",
    "tail_numbers, schedule_ids, flight_numbers = [], [], []\n",
    "aircrafts = []\n",
    "idx = 1\n",
    "\n",
    "# schedule_id - index map\n",
    "schedule_idx = {}\n",
    "for i in range(len(flight_df)):\n",
    "    if flight_df[\"ScheduleId\"][i] not in schedule_idx:\n",
    "        schedule_idx[flight_df[\"ScheduleId\"][i]] = i\n",
    "\n",
    "for i in range(len(schedule_df)):\n",
    "    tn = schedule_df[\"AircraftTailNumber\"][i]\n",
    "    schedule_ids.append(schedule_df[\"ScheduleID\"][i])\n",
    "    flight_numbers.append(int(schedule_df[\"FlightNumber\"][i]))\n",
    "\n",
    "    tc, ti = (\n",
    "        int(flight_df[\"TotalCapacity\"][schedule_idx[schedule_df[\"ScheduleID\"][i]]]),\n",
    "        flight_df[\"TotalInventory\"][schedule_idx[schedule_df[\"ScheduleID\"][i]]],\n",
    "    )\n",
    "\n",
    "    # print sum of FC_CD,BC_CD,PC_CD,EC_CD\n",
    "    tp = 0\n",
    "    keys = \"FC_CD,BC_CD,PC_CD,EC_CD\".split(\",\")\n",
    "    for k in keys:\n",
    "        tp += sum(ast.literal_eval(flight_df[k][schedule_idx[schedule_df[\"ScheduleID\"][i]]]).values())\n",
    "    # print(tp, tc, ti)\n",
    "\n",
    "    if tn not in tail_numbers:\n",
    "        aircrafts.append(\n",
    "            {\n",
    "                \"id\": idx,\n",
    "                \"model\": schedule_df[\"AircraftType\"][i],\n",
    "                \"registration\": schedule_df[\"AircraftTailNumber\"][i],\n",
    "                \"owner_code\": \"\",\n",
    "                \"owner_name\": \"\",\n",
    "                \"total_capacity\": tc,\n",
    "                \"total_inventory\": ti,\n",
    "            }\n",
    "        )\n",
    "        idx += 1\n",
    "        tail_numbers.append(tn)\n",
    "\n",
    "\n",
    "tail_numbers = list(set(tail_numbers))\n",
    "tail_numbers, len(tail_numbers)\n",
    "\n",
    "len(schedule_ids), len(flight_numbers)\n",
    "# aircrafts\n",
    "# schedule_ids, flight_numbers are one-to-one mapping hence this is redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum([42,85,127,170]))\n",
    "f1 = {'F': 25, 'P': 17}\n",
    "f2 = {'C': 34, 'J': 26, 'Z': 26}\n",
    "f3 = {'Q': 38, 'R': 25, 'S': 13, 'T': 13, 'H': 25, 'M': 13}\n",
    "f4 = {'Y': 13, 'A': 13, 'B': 6, 'D': 6, 'E': 6, 'G': 13, 'I': 6, 'K': 13, 'L': 6, 'N': 6, 'O': 6, 'U': 13, 'V': 6, 'W': 6, 'X': 6}\n",
    "\n",
    "# (42, 86, 127, 125)\n",
    "sum([sum(f1.values()), sum(f2.values()), sum(f3.values()), sum(f4.values())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aircrafts = pd.read_csv(\"aircrafts.csv\")\n",
    "df_seat_distribution = pd.read_csv(\"seat-distribution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_aircrafts = pd.DataFrame(columns=df_aircrafts.columns, index=df_aircrafts.index)\n",
    "id_aircraft = 0\n",
    "set_aircrafts = set(zip(schedule_df['AircraftType'], schedule_df['AircraftTailNumber']))\n",
    "for aircraft_type, tail_number in set_aircrafts:\n",
    "    df_new_aircrafts.loc[id_aircraft] = [id_aircraft+1, aircraft_type, aircraft_type, tail_number, tail_number, aircraft_type, 0, 0]\n",
    "    id_aircraft += 1\n",
    "df_new_aircrafts = df_new_aircrafts.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_seat_distribution = pd.DataFrame(columns=df_seat_distribution.columns, index=range(len(df_seat_distribution)))\n",
    "\n",
    "id_seat = 0\n",
    "set_seat_dist = set(zip(flight_df['AircraftType'],flight_df['FC_CD'], flight_df['BC_CD'], flight_df['PC_CD'], flight_df['EC_CD']))\n",
    "# print(len(set_seat_dist))\n",
    "for aircraft_type,fc_cd, bc_cd, pc_cd, ec_cd in set_seat_dist:\n",
    "\n",
    "    fc_cd_dict, bc_cd_dict, pc_cd_dict, ec_cd_dict  = list(map(ast.literal_eval, [fc_cd, bc_cd, pc_cd, ec_cd]))\n",
    "    total_capacity = 0    \n",
    "    needed_aircraft_df = df_new_aircrafts[df_new_aircrafts['model'] == aircraft_type]\n",
    "    \n",
    "    for fc in fc_cd_dict:\n",
    "        for aircraft_id in needed_aircraft_df['id']:\n",
    "            df_new_seat_distribution.loc[id_seat] = (aircraft_id, fc, fc_cd_dict[fc])\n",
    "            id_seat += 1\n",
    "        total_capacity += fc_cd_dict[fc]\n",
    "    for bc in bc_cd_dict:\n",
    "        for aircraft_id in needed_aircraft_df['id']:\n",
    "            df_new_seat_distribution.loc[id_seat] = (aircraft_id, bc, bc_cd_dict[bc])\n",
    "            id_seat += 1\n",
    "        total_capacity += bc_cd_dict[bc]\n",
    "    for pc in pc_cd_dict:\n",
    "        for aircraft_id in needed_aircraft_df['id']:\n",
    "            df_new_seat_distribution.loc[id_seat] = (aircraft_id, pc, pc_cd_dict[pc])\n",
    "            id_seat += 1\n",
    "        total_capacity += pc_cd_dict[pc]\n",
    "    for ec in ec_cd_dict:\n",
    "        for aircraft_id in needed_aircraft_df['id']:\n",
    "            df_new_seat_distribution.loc[id_seat] = (aircraft_id, ec, ec_cd_dict[ec])\n",
    "            id_seat += 1\n",
    "        total_capacity += ec_cd_dict[ec]\n",
    "\n",
    "    \n",
    "    for index, row in needed_aircraft_df.iterrows():\n",
    "        row.total_capacity = total_capacity\n",
    "        row.total_inventory = total_capacity\n",
    "        df_new_aircrafts.loc[index] = row\n",
    "        \n",
    "    \n",
    "    \n",
    "df_new_seat_distribution = df_new_seat_distribution.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_aircrafts.to_csv('aircrafts.csv', index=False)\n",
    "df_new_seat_distribution.to_csv('seat-distribution.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
